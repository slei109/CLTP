basic {
  # Edit this
  data_dir = ./
  download_dir = ${basic.data_dir}/download  # dir that contains downloaded dataset
  log_root = ${basic.data_dir}
}

#*************** Dataset-specific config ***************
# Do not have overlapping attributes with model config later

dataset = ${basic} {
  max_segment_len = 128
}

#*************** Model-specific config ***************

model {
  # Learning
  num_epochs = 4
  batch_size = 32
  eval_batch_size = 64
  gradient_accumulation_steps = 1
  bert_learning_rate = 2e-5
  adam_eps = 1e-8
  adam_weight_decay = 1e-4
  warmup_ratio = 0.1
  max_grad_norm = 1  # Set 0 to disable clipping
  dropout_rate = 0.1
  freeze_emb = false
  dim_reduce = false  # Integer as divisor

  # Uncertainty
  lang_un = false
  evi_un = true

  ## Partial Label
  partial = false
  full_label = false
  sigmoid_loss_weight = 1
  lw_of_first_term = 1

  # Other
  eval_frequency = 5000
  report_frequency = 1000

  dataset_name = xnli
  self_learning = false
}

model_sl = ${model} {
  self_learning = true
  sl_max_itr = 8
  sl_num_epochs = 6
  sl_en_ratio = 0.2
  sl_lang_ratio = 0  # Sampling ratio of previous selected; 0 to disable
  sl_criterion = dissonance
  sl_top_k_ratio = 0.01  # For selection; Per lang per class/type
  sl_selection_threshold = false  # For selection
  sl_gold_labels = false  # Only true for debugging
  sl_filter_sel_by_gold = false  # Only true for debugging; 1 to disable mismatch from gold
  eval_frequency = 500
  report_frequency = 500
}

#*************** Experiment-specific config: baseline ***************

xlmr_large_zero_shot = ${dataset} ${model} {
  model_type = xlmr
  pretrained = xlm-roberta-large
  zero_shot = true
  dim_reduce = 128
}

#*************** Experiment-specific config: SL ***************

xlmr_large_zero_shot_sl = ${dataset} ${model_sl} {
  model_type = xlmr
  pretrained = xlm-roberta-large
  init_config_name = xlmr_large_zero_shot ##### dir that contains trained results of xlmr_large_zero_shot
  init_suffix = ##### filename that contains trained results of xlmr_large_zero_shot
  dim_reduce = 128
  zero_shot = true
  sl_criterion = dissonance
  sl_max_itr = 5
  sl_en_ratio = 0.01
  sl_top_k_ratio = 0.08
  sl_lang_ratio = 1
  sl_num_epochs = 3
}


#*************** Experiment-specific config: PartialSL ***************

xlmr_large_zero_shot_parial_sl = ${xlmr_large_zero_shot_sl} {
    bert_learning_rate = 2e-7
    init_config_name = xlmr_large_zero_shot_sl ##### dir that contains trained results of xlmr_large_zero_shot_sl
    init_suffix = ##### filename that contains trained results of xlmr_large_zero_shot_sl
    partial = true
}